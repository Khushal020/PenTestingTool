from datetime import datetime as dt
import sys, random, optparse
import requests
from requests.packages.urllib3.exceptions import InsecureRequestWarning
import urllib.request as req

requests.packages.urllib3.disable_warnings(InsecureRequestWarning)


def get_user_agent():
    custom_headers = {"User-Agent" : "Mozilla/5.0 (Windows NT {}; rv:{}.0) Gecko/20100101 Firefox/{}.0".format(random.randint(7,11),
                                                                                                           random.randint(40,50),
                                                                                                           random.randint(35,50))}

    return custom_headers

def adjustDomainName(domain):#correct domain name for urllib
    url = domain
    if url.startswith('https'):
        url = url.replace('https://', '')
    if url.startswith('http'):
        url = url.replace('http://', '')
    if url.startswith('www'):
        url = url.replace('www.', '')

    url = url.replace('/', '')
    domain = url
    print(domain)

    if not domain.startswith("http"):
        domain = "http://" + domain


    
    return domain

def loadWordList(wordlist_file, ext):#load pages to check from dictionary
    try:
        with open(wordlist_file, encoding="utf8") as wlf:
            content = wlf.readlines()
        for i in range(len(content)):
            content[i] = content[i].strip("\n")
        if ext.lower() == "a":
            return content
        else:
            return [element for element in content if element.endswith(ext) or element.endswith("/")]
    except FileNotFoundError:
        sys.exit("Couldn't find wordlist file!")

def saveResults(file_name, found_pages, progress=0):
    now = dt.now()
    with open("admin_sniffer_results.txt", "w") as f:
        stamp = "%d-%d-%d %d: %d: %d" % (now.year, now.month, now.day, now.hour, now.minute, now.second)
        print(stamp, file=f)
        for page in found_pages:
            print(page, file=f)
        print("total progress: %d\n______________________________________________" % progress, file=f)


def main(domain, progress=0, ext="a", strict=False, save=True, visible=True, wordlist_file="admin_login.txt"):
    count = 0

    print("working... press ctrl+c at any point to abort...")
    #resp_codes = {403 : "request forbidden", 401 : "authentication required"}#HTTP response codes
    found = []#list to hold the results we find
    domain = adjustDomainName(domain)#correct domain name for urllib

    print("loading wordlist...")
    attempts = loadWordList(wordlist_file, ext)
    print("crawling...")
    
    for link in attempts[progress:]:#loop over every page in the wordlist file
        try:
            if link.startswith('/'):
                site = domain + link
            else:
                site = domain + '/' + link

            try:
                resp = requests.get(site, headers=get_user_agent(), verify=False)
                
                code = resp.status_code
                if code == 200:
                    found.append(site)
                    count += 1
                    if count > 10:
                        print("It seems like given URL does not have admin panel according to our wordlist!!!")
                        break
                    print("\033[1;32m[+]\033[0m %s ADMIN PAGE VALID!" % site)

                elif code == 404:
                    print("\033[1;31m[-]\033[1;m %s PAGE NOT FOUND!" % site)
                        
                else:
                    print("\033[1;30m[!]\033[1;m %s POTENTIAL POSITIVE.. Request forbidden or Authentication required" % (site))
            except:
                print("invalid link or no internet connection!")
                break
            progress += 1
            
        except KeyboardInterrupt:#make sure we don't lose everything should the user get bored
            print()
            break

    if count<=10:
        if save:#save results to a text file
            print("Saving results...")
            saveResults("admin_sniffer_results.txt", found)

            print("results saved to admin_sniffer_results.txt...")

        print("found the following results: " + "  ".join(found) + " total progress: %s" % progress)


def getRobotsFile(domain):
    print("Attempting to get robots.txt file...")
    found = []
    domain = adjustDomainName(domain)#correct domain name for urllib
    
    robots_file = domain + "/robots.txt"
    try:
        data = req.urlopen(robots_file).read().decode("utf-8")
        for element in data.split("\n"):
            if element.startswith("Disallow:"):
                panel_page = domain + element[10:]
                print("Disallow rule found: %s" % (panel_page))
                found.append(panel_page)
        if found:
            print("admin panels found... Saving results to file...")
            saveResults("admin_sniffer_results.txt", found, 0)
            print("done...")
        else:
            print("could not find any panel pages in the robots file...")
    except Exception as e:
        print(e)
        print('Could not find any robots.txt file')

def breacher():
    domain = input("Please enter target domain: ")

    wordlist = 'admin_login.txt'

    getRobotsFile(domain)
    main(domain, wordlist_file=wordlist)


if __name__ == "__main__":
    breacher()


