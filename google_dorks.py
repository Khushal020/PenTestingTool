from __future__ import print_function
from googlesearch import search

import sys
import time
import random
from urllib.parse import urlparse


def logger(log, data):
    file = open((log) + ".txt", "a")
    file.write(str(data))
    file.write("\n")
    file.close()

def get_user_agent():
    with open('user_agent.txt', 'r') as all_user_agent:
        user_agent_list = [_.strip() for _ in all_user_agent.readlines()]

    return random.choice(user_agent_list)


def dorks():

    try:
        data = input("\n[+] Do You Like To Save The Output In A File? (Y/N) ").strip()
        log = ("")

    except KeyboardInterrupt:
            print ("\n")
            print ("\033[1;91m[!] User Interruption Detected..!\033[0")
            time.sleep(0.5)
            sys.exit(1)

    if data.startswith("y") or data.startswith('Y'):
        log = input("[~] Give The File a Name: ")
        print ("\n" + "  " + "»" * 78 + "\n")
    else:
        print ("[!] Saving is Skipped...")
        print ("\n" + "  " + "»" * 78 + "\n")

    try:
        with open('temp.txt', 'r') as temp:
            splited = temp.read().split(' ')
            url = splited[0]
            counter = int(splited[1])
    except:
        url = ''
        counter = 0

    if url != '':
        flag = input("Do you want to continue with " + url + " then Y else N [Y/N]: ")
        if flag == 'Y' or flag == 'y':
            pass
        else:
            url = input('Enter the target URL: ')

            if url.startswith('https'):
                url = url.replace('https://', '')
            if url.startswith('http'):
                url = url.replace('http://', '')
            if url.startswith('www'):
                url = url.replace('www.', '')

            url = url.replace('/', '')
            counter = 0
    else:
        url = input('Enter the target URL: ')

        if url.startswith('https'):
            url = url.replace('https://', '')
        if url.startswith('http'):
            url = url.replace('http://', '')
        if url.startswith('www'):
            url = url.replace('www.', '')

        url = url.replace('/', '')
        counter = 0

    with open('new_google_Dorks.txt', 'r') as dorks:
        lines = dorks.readlines()

    for line in lines[counter:]:
        try:
            dork = line.replace('\n', '') + ' site:' + url
            amount = 20
            requ = 0
            user_agent = get_user_agent()

            for results in search(dork, tld="com", lang="en", num=int(amount), start=0, stop=None, pause=2, user_agent=user_agent, verify_ssl=False):
                requ += 1
                print ("\033[1;32m[+]\033[0m ", requ, results)
                if url in urlparse(results).netloc:
                    print ("\033[1;32m[+]\033[0m ", counter, results)
                    data = (counter, results)
                    logger(log, data)
                time.sleep(3600)
                
                if counter == len(lines):
                    with open('temp.txt', 'w') as temp:
                        temp.write(url + ' ' + str(0))
                if requ >= int(amount):
                    break

            counter += 1

        except KeyboardInterrupt:
            print ("\n")
            with open('temp.txt', 'w') as temp:
                temp.write(url + ' ' + str(counter))
            print ("\033[1;91m[!] User Interruption Detected..!\033[0")
            time.sleep(0.5)
            sys.exit(1)

        except Exception as e:
            print("****************429 TOO MANY REQUESTS***************")
            print("For requesting multiple times on same server caused \nThrowing an error so Try after 60-90 minutes later\nOr try to run on different network and machine")
            with open('temp.txt', 'w') as temp:
                temp.write(url + ' ' + str(counter))
            sys.exit()
            
    sys.exit()


# =====# Main #===== #
if __name__ == "__main__":
    dorks()
